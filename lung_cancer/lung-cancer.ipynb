{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1079953,"sourceType":"datasetVersion","datasetId":601280}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Import needed libraries**","metadata":{}},{"cell_type":"code","source":"# import system libs\nimport os\nimport itertools\n\n# import data handling tools\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\n\n# import Deep learning Libraries\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.applications import EfficientNetB3\n\n# ignore the warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:29:05.802199Z","iopub.execute_input":"2024-03-16T06:29:05.8028Z","iopub.status.idle":"2024-03-16T06:29:05.81525Z","shell.execute_reply.started":"2024-03-16T06:29:05.80277Z","shell.execute_reply":"2024-03-16T06:29:05.814446Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Loading the dataset**\n\n> Read the training dataset into the dataframe","metadata":{}},{"cell_type":"code","source":"# loading the dataset\ndef loading_the_data(data_dir):\n    # Generate data paths with labels\n    filepaths = []\n    labels = []\n\n    # Get folder names\n    folds = os.listdir(data_dir)\n\n    for fold in folds:\n        foldpath = os.path.join(data_dir, fold)\n        filelist = os.listdir(foldpath)\n        for file in filelist:\n            fpath = os.path.join(foldpath, file)\n            \n            filepaths.append(fpath)\n            labels.append(fold)\n\n    # Concatenate data paths with labels into one DataFrame\n    Fseries = pd.Series(filepaths, name='filepaths')\n    Lseries = pd.Series(labels, name='labels')\n\n    df = pd.concat([Fseries, Lseries], axis=1)\n    \n    return df\n\n\n# change label names to its original names\ndef change_label_names(df, column_name):\n    index = {'lung_aca': 'Lung_adenocarcinoma', 'lung_n': 'Lung_benign_tissue', 'lung_scc': 'Lung squamous_cell_carcinoma'}\n\n\n    df[column_name] = df[column_name].replace(index)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:49:26.021948Z","iopub.execute_input":"2024-03-16T05:49:26.022595Z","iopub.status.idle":"2024-03-16T05:49:26.03088Z","shell.execute_reply.started":"2024-03-16T05:49:26.022561Z","shell.execute_reply":"2024-03-16T05:49:26.029872Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# loading the data\ndata_dir = '/kaggle/input/lung-and-colon-cancer-histopathological-images/lung_colon_image_set/lung_image_sets'\ndf = loading_the_data(data_dir)\n\nchange_label_names(df, 'labels')\n\ndf","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:49:26.386296Z","iopub.execute_input":"2024-03-16T05:49:26.386598Z","iopub.status.idle":"2024-03-16T05:49:26.448117Z","shell.execute_reply.started":"2024-03-16T05:49:26.386573Z","shell.execute_reply":"2024-03-16T05:49:26.447234Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Data preprocessing**\n\nfirst we will check if the training data is balanced or not","metadata":{}},{"cell_type":"code","source":"data_balance = df.labels.value_counts()\n\n\ndef custom_autopct(pct):\n    total = sum(data_balance)\n    val = int(round(pct*total/100.0))\n    return \"{:.1f}%\\n({:d})\".format(pct, val)\n\n\n# pie chart for data balance\nplt.pie(data_balance, labels = data_balance.index, autopct=custom_autopct, colors = [\"#2092E6\",\"#6D8CE6\",\"#20D0E6\"])\nplt.title(\"Training data balance\")\nplt.axis(\"equal\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:49:26.907545Z","iopub.execute_input":"2024-03-16T05:49:26.908235Z","iopub.status.idle":"2024-03-16T05:49:27.070771Z","shell.execute_reply.started":"2024-03-16T05:49:26.908204Z","shell.execute_reply":"2024-03-16T05:49:27.069509Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"It is balanced, now we will split our data to train, val and test set","metadata":{}},{"cell_type":"code","source":"# data --> 80% train data && 20% (test, val)\ntrain_df, ts_df = train_test_split(df, train_size = 0.8, shuffle = True, random_state = 42)\n\n# test data --> 10% train data && 10% (test, val)\nvalid_df, test_df = train_test_split(ts_df, train_size = 0.5, shuffle = True, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:49:27.256721Z","iopub.execute_input":"2024-03-16T05:49:27.257396Z","iopub.status.idle":"2024-03-16T05:49:27.26787Z","shell.execute_reply.started":"2024-03-16T05:49:27.257365Z","shell.execute_reply":"2024-03-16T05:49:27.266993Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Create image data generator**\n\nin this step we will convert the whoole data to numpy arrays","metadata":{}},{"cell_type":"code","source":"# crobed image size\nbatch_size = 32\nimg_size = (224, 224)\n\ntr_gen = ImageDataGenerator(rescale=1. / 255)\nts_gen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\nvalid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n\ntest_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                    color_mode= 'rgb', shuffle= False, batch_size= batch_size)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:49:27.638865Z","iopub.execute_input":"2024-03-16T05:49:27.639253Z","iopub.status.idle":"2024-03-16T05:49:51.580403Z","shell.execute_reply.started":"2024-03-16T05:49:27.639222Z","shell.execute_reply":"2024-03-16T05:49:51.579491Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Display sample from train data**","metadata":{}},{"cell_type":"code","source":"g_dict = train_gen.class_indices      # defines dictionary {'class': index}\nclasses = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\nimages, labels = next(train_gen)      # get a batch size samples from the generator\n\n# ploting the patch size samples\nplt.figure(figsize= (20, 20))\n\nfor i in range(batch_size):\n    plt.subplot(6, 6, i + 1)\n    image = images[i]\n    plt.imshow(image)\n    index = np.argmax(labels[i])  # get image index\n    class_name = classes[index]   # get class of image\n    plt.title(class_name, color= 'black', fontsize= 16)\n    plt.axis('off')\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:53:02.560057Z","iopub.execute_input":"2024-03-16T05:53:02.560953Z","iopub.status.idle":"2024-03-16T05:53:11.218587Z","shell.execute_reply.started":"2024-03-16T05:53:02.560919Z","shell.execute_reply":"2024-03-16T05:53:11.216412Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Create needed functions**","metadata":{}},{"cell_type":"code","source":"# Displaying the model performance\ndef model_performance(history, Epochs):\n    # Define needed variables\n    tr_acc = history.history['accuracy']\n    tr_loss = history.history['loss']\n    val_acc = history.history['val_accuracy']\n    val_loss = history.history['val_loss']\n    \n    Epochs = [i+1 for i in range(len(tr_acc))]\n    \n    # Plot training history\n    plt.figure(figsize= (20, 8))\n    plt.style.use('fivethirtyeight')\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n    plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n    plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.tight_layout\n    plt.show()\n    \n\n# Evaluate the model\ndef model_evaluation(model):\n    train_score = model.evaluate(train_gen, verbose= 1)\n    valid_score = model.evaluate(valid_gen, verbose= 1)\n    test_score = model.evaluate(test_gen, verbose= 1)\n    \n    print(\"Train Loss: \", train_score[0])\n    print(\"Train Accuracy: \", train_score[1])\n    print('-' * 20)\n    print(\"Validation Loss: \", valid_score[0])\n    print(\"Validation Accuracy: \", valid_score[1])\n    print('-' * 20)\n    print(\"Test Loss: \", test_score[0])\n    print(\"Test Accuracy: \", test_score[1])\n    \n\n# Get Predictions\ndef get_pred(model, test_gen):\n    \n    preds = model.predict(test_gen)\n    y_pred = np.argmax(preds, axis = 1)\n    \n    return y_pred\n\n\n# Confusion Matrix\ndef plot_confusion_matrix(test_gen, y_pred):\n    \n    g_dict = test_gen.class_indices\n    classes = list(g_dict.keys())\n    \n    # Display the confusion matrix\n    cm = confusion_matrix(test_gen.classes, y_pred)\n\n    plt.figure(figsize= (10, 10))\n    plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n    plt.title('Confusion Matrix')\n    plt.colorbar()\n    \n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation= 45)\n    plt.yticks(tick_marks, classes)\n    \n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n    \n    \n    plt.tight_layout()\n    plt.ylabel('True Label')\n    plt.xlabel('Predicted Label')\n    \n    plt.show()\n    \n    \n# Defining a convolutional NN block for a sequential CNN model\ndef conv_block(filters, act='relu'):\n    \n    block = Sequential()\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(Conv2D(filters, 3, activation=act, padding='same'))\n    block.add(BatchNormalization())\n    block.add(MaxPooling2D())\n    \n    return block\n\n\n# Defining a dense NN block for a sequential CNN model\ndef dense_block(units, dropout_rate, act='relu'):\n    \n    block = Sequential()\n    block.add(Dense(units, activation=act))\n    block.add(BatchNormalization())\n    block.add(Dropout(dropout_rate))\n    \n    return block","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:21:06.394045Z","iopub.execute_input":"2024-03-16T06:21:06.394463Z","iopub.status.idle":"2024-03-16T06:21:06.415312Z","shell.execute_reply.started":"2024-03-16T06:21:06.394433Z","shell.execute_reply":"2024-03-16T06:21:06.414266Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Model Structure**","metadata":{}},{"cell_type":"markdown","source":"# **CNN model**","metadata":{}},{"cell_type":"code","source":"# create Model structure\nimg_size = (224, 224)\nchannels = 3\nimg_shape = (img_size[0], img_size[1], channels)\n\nclass_counts = len(list(train_gen.class_indices.keys()))     # to define number of classes in dense layer","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:54:17.531396Z","iopub.execute_input":"2024-03-16T05:54:17.531744Z","iopub.status.idle":"2024-03-16T05:54:17.538941Z","shell.execute_reply.started":"2024-03-16T05:54:17.531717Z","shell.execute_reply":"2024-03-16T05:54:17.538138Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model architecture\ncnn_model = Sequential()\n\n# first conv block\ncnn_model.add(Conv2D(filters=16, kernel_size=(3,3), padding=\"same\", activation=\"relu\", input_shape= img_shape))\ncnn_model.add(BatchNormalization())\ncnn_model.add(MaxPooling2D())\n\n# second conv block\ncnn_model.add(conv_block(32))\n\n# third conv block\ncnn_model.add(conv_block(64))\n\n# fourth conv bolck\ncnn_model.add(conv_block(128))\n\n# fifth conv block\ncnn_model.add(conv_block(256))\n\n# flatten layer\ncnn_model.add(Flatten())\n\n# first dense block\ncnn_model.add(dense_block(128, 0.5))\n\n# second dense block\ncnn_model.add(dense_block(64, 0.3))\n\n# third dense block\ncnn_model.add(dense_block(32, 0.2))\n\n# output layer\ncnn_model.add(Dense(class_counts, activation = \"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:54:18.285586Z","iopub.execute_input":"2024-03-16T05:54:18.285949Z","iopub.status.idle":"2024-03-16T05:54:18.555818Z","shell.execute_reply.started":"2024-03-16T05:54:18.285923Z","shell.execute_reply":"2024-03-16T05:54:18.554865Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cnn_model.compile(Adamax(learning_rate= 0.001), loss= 'categorical_crossentropy', metrics= ['accuracy'])\n\ncnn_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:54:18.895266Z","iopub.execute_input":"2024-03-16T05:54:18.896067Z","iopub.status.idle":"2024-03-16T05:54:18.928761Z","shell.execute_reply.started":"2024-03-16T05:54:18.896034Z","shell.execute_reply":"2024-03-16T05:54:18.927922Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train the model\nepochs = 20   # number of all epochs in training\n\nhistory = cnn_model.fit(train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen, shuffle= False)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T05:54:19.953485Z","iopub.execute_input":"2024-03-16T05:54:19.953813Z","iopub.status.idle":"2024-03-16T06:15:31.748912Z","shell.execute_reply.started":"2024-03-16T05:54:19.953789Z","shell.execute_reply":"2024-03-16T06:15:31.748062Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Display model performance**","metadata":{}},{"cell_type":"code","source":"# Display model performance\nmodel_performance(history, epochs)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:21:13.868263Z","iopub.execute_input":"2024-03-16T06:21:13.86899Z","iopub.status.idle":"2024-03-16T06:21:14.55338Z","shell.execute_reply.started":"2024-03-16T06:21:13.868959Z","shell.execute_reply":"2024-03-16T06:21:14.552381Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Evaluate the model**","metadata":{}},{"cell_type":"code","source":"# Model evaluation\nmodel_evaluation(cnn_model)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T06:21:27.140664Z","iopub.execute_input":"2024-03-16T06:21:27.141538Z","iopub.status.idle":"2024-03-16T06:22:38.952021Z","shell.execute_reply.started":"2024-03-16T06:21:27.141502Z","shell.execute_reply":"2024-03-16T06:22:38.951136Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Get predictions and display the confusion matrix**","metadata":{}},{"cell_type":"code","source":"# get predictions\ny_pred = get_pred(cnn_model, test_gen)\n\n# plot the confusion matrix\nplot_confusion_matrix(test_gen, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:20:22.160249Z","iopub.execute_input":"2024-03-16T07:20:22.161104Z","iopub.status.idle":"2024-03-16T07:20:30.103016Z","shell.execute_reply.started":"2024-03-16T07:20:22.161055Z","shell.execute_reply":"2024-03-16T07:20:30.102035Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **EfficientNetB3**","metadata":{}},{"cell_type":"code","source":"# get the pre-trained model (EfficientNetB3)\nbase_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape = img_shape, pooling= None)\n\n# fine-tune EfficientNetB3 (Adding some custom layers on top)\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = BatchNormalization()(x)\nx = dense_block(128, 0.5)(x)\nx = dense_block(32, 0.2)(x)\npredictions = Dense(class_counts, activation = \"softmax\")(x)    # output layer with softmax activation\n\n# the model\nEfficientNetB3_model = Model(inputs = base_model.input, outputs = predictions)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:21:51.201858Z","iopub.execute_input":"2024-03-16T07:21:51.20263Z","iopub.status.idle":"2024-03-16T07:21:53.067624Z","shell.execute_reply.started":"2024-03-16T07:21:51.202586Z","shell.execute_reply":"2024-03-16T07:21:53.066831Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EfficientNetB3_model.compile(optimizer=Adamax(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n\nEfficientNetB3_model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:21:56.544828Z","iopub.execute_input":"2024-03-16T07:21:56.54534Z","iopub.status.idle":"2024-03-16T07:21:57.068623Z","shell.execute_reply.started":"2024-03-16T07:21:56.545309Z","shell.execute_reply":"2024-03-16T07:21:57.067738Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train the model\nepochs = 20   # number of all epochs in training\n\nEfficientNetB3_history = EfficientNetB3_model.fit(train_gen, epochs= epochs, verbose= 1, validation_data= valid_gen, shuffle= False)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:22:07.226726Z","iopub.execute_input":"2024-03-16T07:22:07.227459Z","iopub.status.idle":"2024-03-16T07:59:02.323995Z","shell.execute_reply.started":"2024-03-16T07:22:07.227424Z","shell.execute_reply":"2024-03-16T07:59:02.323029Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Display model performance**","metadata":{}},{"cell_type":"code","source":"# Display model performance\nmodel_performance(EfficientNetB3_history, epochs)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:59:29.128167Z","iopub.execute_input":"2024-03-16T07:59:29.128997Z","iopub.status.idle":"2024-03-16T07:59:29.976022Z","shell.execute_reply.started":"2024-03-16T07:59:29.128959Z","shell.execute_reply":"2024-03-16T07:59:29.974978Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Evaluate the model**","metadata":{}},{"cell_type":"code","source":"# Model evaluation\nmodel_evaluation(EfficientNetB3_model)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T07:59:38.474353Z","iopub.execute_input":"2024-03-16T07:59:38.474719Z","iopub.status.idle":"2024-03-16T08:00:43.205134Z","shell.execute_reply.started":"2024-03-16T07:59:38.474688Z","shell.execute_reply":"2024-03-16T08:00:43.204201Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Get predictions and display the confusion matrix**","metadata":{}},{"cell_type":"code","source":"# get predictions\ny_pred = get_pred(EfficientNetB3_model, test_gen)\n\n# plot the confusion matrix\nplot_confusion_matrix(test_gen, y_pred)","metadata":{"execution":{"iopub.status.busy":"2024-03-16T08:01:02.362644Z","iopub.execute_input":"2024-03-16T08:01:02.363033Z","iopub.status.idle":"2024-03-16T08:01:25.970541Z","shell.execute_reply.started":"2024-03-16T08:01:02.363Z","shell.execute_reply":"2024-03-16T08:01:25.9695Z"},"trusted":true},"outputs":[],"execution_count":null}]}